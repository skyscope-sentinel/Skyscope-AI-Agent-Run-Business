# Create comprehensive documentation
docs_content = '''# Skyscope RAG System Documentation

## ğŸš€ Overview

The Skyscope RAG System is a comprehensive Retrieval-Augmented Generation platform designed to index, search, and leverage your massive GitHub codebase (115M+ files in Parquet format) for advanced code generation, completion, and reasoning using local Ollama models.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Skyscope RAG System                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Parquet   â”‚  â”‚  Semantic   â”‚  â”‚  Keyword    â”‚     â”‚
â”‚  â”‚   Indexer   â”‚  â”‚   Search    â”‚  â”‚   Search    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Ollama    â”‚  â”‚   Agent     â”‚  â”‚   Memory    â”‚     â”‚
â”‚  â”‚ Integration â”‚  â”‚ Framework   â”‚  â”‚ Management  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Installation & Setup

### Prerequisites
- macOS (tested on macOS 13+)
- Python 3.8+
- Ollama installed locally
- At least 16GB RAM (32GB+ recommended)
- 100GB+ free disk space for indexes

### Quick Setup
```bash
cd /home/user/skyscope_rag
python scripts/setup.py
```

### Manual Setup
```bash
# Install dependencies
pip install sentence-transformers faiss-cpu pyarrow pandas numpy requests aiohttp psutil

# Start Ollama
ollama serve

# Pull recommended models
ollama pull codellama
ollama pull nomic-embed-text
ollama pull llama2-code
```

## ğŸ“Š Core Components

### 1. Parquet Code Indexer
- **Purpose**: Process and index GitHub code files from Parquet format
- **Features**:
  - Batch processing with deduplication
  - Language detection (32+ languages)
  - Content chunking for semantic search
  - SQLite database with FTS5 full-text search
  - Embedding vector storage

### 2. Semantic Search Engine
- **Model**: sentence-transformers/all-MiniLM-L6-v2 (384 dimensions)
- **Features**:
  - Local embedding generation
  - Cosine similarity search
  - Threshold-based filtering
  - Batch processing support

### 3. Keyword Search Engine
- **Technology**: SQLite FTS5
- **Features**:
  - Fast full-text search
  - Language/license filtering
  - Ranking and relevance scoring
  - Boolean query support

### 4. Hybrid Search
- **Combines**: Keyword + Semantic search results
- **Scoring**: Weighted combination with deduplication
- **Optimization**: Relevance boosting for multi-match results

### 5. Ollama RAG Integration
- **Models**: Support for all Ollama models
- **Features**:
  - Dynamic model switching
  - Context-aware prompting
  - Streaming responses
  - Temperature/parameter control

### 6. Agent Execution Framework
- **Terminal Agent**: Safe command execution with timeout
- **Memory Manager**: Persistent state storage
- **Code Execution**: Python script execution with safety checks
- **Browser Integration**: Ready for browser automation

## ğŸ“ Directory Structure

```
/home/user/skyscope_rag/
â”œâ”€â”€ indexes/           # SQLite databases and search indexes
â”œâ”€â”€ embeddings/        # Cached embedding vectors
â”œâ”€â”€ cache/            # Temporary files and caches
â”œâ”€â”€ logs/             # System logs
â”œâ”€â”€ config/           # Configuration files
â”œâ”€â”€ agents/           # Agent-specific data
â”œâ”€â”€ models/           # Model-specific configurations
â”œâ”€â”€ scripts/          # Executable scripts
â””â”€â”€ memory/           # Persistent memory storage
```

## ğŸ” Usage Examples

### Index Your Parquet Files
```python
from rag_system import SkyscopeRAGSystem

system = SkyscopeRAGSystem()
result = system.index_parquet_files("/Users/skyscope.cloud/Documents/github-code")
print(f"Indexed {result['total_processed']} files")
```

### Search the Codebase
```python
# Keyword search
results = system.search("REST API implementation", search_type="keyword", language="python")

# Semantic search
results = system.search("machine learning algorithms", search_type="semantic")

# Hybrid search (recommended)
results = system.search("data visualization", search_type="hybrid", max_results=20)
```

### RAG-Enhanced Q&A
```python
# Ask questions about your codebase
response = system.ask("How do I implement JWT authentication in Flask?")
print(response['rag_response'])

# Execute found code (with safety checks)
response = system.ask("Show me a Python function to parse JSON", execute_code=True)
```

### Model Management
```python
# Switch Ollama models
system.switch_ollama_model("llama2-code")
system.switch_ollama_model("codellama:13b")

# Get available models
stats = system.get_stats()
print(stats['available_ollama_models'])
```

## ğŸ–¥ï¸ Command Line Interface

### Basic Commands
```bash
# Index parquet files
python scripts/main.py index /Users/skyscope.cloud/Documents/github-code --max-files 10

# Search codebase
python scripts/main.py search "neural network implementation" --language python --max-results 15

# Ask questions
python scripts/main.py ask "How to optimize database queries?" --model codellama

# Show statistics
python scripts/main.py stats

# Interactive mode
python scripts/main.py interactive
```

### Advanced Options
```bash
# Search with output to file
python scripts/main.py search "microservices architecture" --output results.json

# Language-specific search
python scripts/main.py search "async programming" --language javascript

# Execute found code
python scripts/main.py ask "Python sorting algorithms" --execute --language python
```

## ğŸ”’ Security Features

### Safe Code Execution
- Command timeout protection (30s default)
- Dangerous pattern detection
- Sandboxed execution environment
- User confirmation for risky operations

### Memory Protection
- Memory usage monitoring
- Process isolation
- Resource limit enforcement
- Automatic cleanup

## âš¡ Performance Optimization

### Indexing Performance
- Parallel processing (20 workers default)
- Batch operations (1000 records/batch)
- Memory-efficient streaming
- Progress tracking and resumption

### Search Performance
- SQLite FTS5 for keyword search
- FAISS for vector similarity (optional)
- Result caching
- Query optimization

### Memory Management
- Embedding cache with LRU eviction
- Lazy loading of large datasets
- Garbage collection optimization
- Memory pool management

## ğŸ”§ Configuration

### Main Config (`config/config.json`)
```json
{
  "system": {
    "name": "Skyscope RAG System",
    "base_dir": "/home/user/skyscope_rag",
    "max_workers": 20,
    "batch_size": 1000
  },
  "indexing": {
    "chunk_size": 8192,
    "overlap": 512,
    "min_file_size": 50,
    "max_file_size": 1048576
  },
  "embeddings": {
    "model": "all-MiniLM-L6-v2",
    "dimension": 384,
    "batch_size": 32
  },
  "ollama": {
    "base_url": "http://localhost:11434",
    "default_model": "codellama",
    "timeout": 300
  }
}
```

## ğŸ”— Integration with Pinokio Apps

### Browser-Use Integration
```python
# Example: Integrate with browser automation
from browser_use import BrowserAgent

browser_agent = BrowserAgent()
search_results = system.search("web scraping techniques")
browser_agent.demonstrate_technique(search_results[0]['content'])
```

### macOS-Use Integration
```python
# Example: System automation
from macos_use import MacOSAgent

macos_agent = MacOSAgent()
code_snippet = system.search("file management utilities")[0]['content']
macos_agent.execute_file_operation(code_snippet)
```

## ğŸ“Š Monitoring & Logging

### System Logs
- Location: `/home/user/skyscope_rag/logs/system.log`
- Levels: DEBUG, INFO, WARNING, ERROR
- Rotation: Daily with 30-day retention

### Performance Metrics
```python
stats = system.get_stats()
# Returns: file counts, language distribution, embedding status, memory usage
```

### Health Checks
```python
# Database integrity
system.indexer._init_database()

# Ollama connectivity
system.rag_engine._get_available_models()

# Memory usage
system.memory_manager.list_keys()
```

## ğŸ› Troubleshooting

### Common Issues

1. **Ollama Connection Failed**
   ```bash
   # Check if Ollama is running
   curl http://localhost:11434/api/tags
   
   # Start Ollama
   ollama serve
   ```

2. **Memory Issues During Indexing**
   ```python
   # Reduce batch size
   system.config['indexing']['batch_size'] = 500
   ```

3. **Slow Search Performance**
   ```python
   # Check index statistics
   stats = system.get_stats()
   print(f"Files indexed: {stats['total_files']}")
   print(f"Embeddings: {stats['chunks_with_embeddings']}")
   ```

4. **Missing Dependencies**
   ```bash
   # Reinstall requirements
   python scripts/setup.py
   ```

## ğŸš€ Advanced Usage

### Custom Embedding Models
```python
# Use different embedding model
embedding_engine = LocalEmbeddingEngine("all-mpnet-base-v2")
system.embedding_engine = embedding_engine
```

### Batch Processing
```python
# Process multiple directories
directories = ["/path/to/parquet1", "/path/to/parquet2"]
for directory in directories:
    result = system.index_parquet_files(directory, max_files=100)
    print(f"Processed {result['total_processed']} files from {directory}")
```

### Custom Search Filters
```python
# Advanced filtering
results = system.search_engine.keyword_search(
    query="authentication",
    language="python",
    license="mit",
    max_results=50
)
```

## ğŸ“ˆ Scaling Considerations

### Large Datasets (100M+ files)
- Use distributed processing
- Implement database sharding
- Consider external vector databases (Weaviate, Pinecone)
- Optimize chunk sizes for your hardware

### Production Deployment
- Use PostgreSQL instead of SQLite
- Implement Redis caching
- Add load balancing
- Monitor resource usage

## ğŸ¤ Contributing

The system is modular and extensible. Key extension points:

1. **Custom Search Engines**: Implement new search backends
2. **Agent Types**: Add browser, file system, or API agents
3. **Embedding Models**: Support for different embedding providers
4. **Output Formats**: Custom result formatting and export

## ğŸ“ API Reference

### Core Methods
- `system.index_parquet_files(directory, max_files=None)`
- `system.search(query, search_type="hybrid", language=None)`
- `system.ask(question, language=None, execute_code=False)`
- `system.switch_ollama_model(model_name)`
- `system.get_stats()`

### Agent Methods
- `execution_agent.search_and_execute(query, execute_code=False)`
- `terminal_agent.execute_command(command, timeout=30)`
- `memory_manager.store(key, value, persistent=False)`

## ğŸ Conclusion

The Skyscope RAG System provides a comprehensive solution for leveraging large codebases with modern AI techniques. It combines the power of local embedding models, efficient search algorithms, and Ollama integration to enable advanced code understanding and generation capabilities.

For support and updates, monitor the system logs and check the configuration files for optimization opportunities.
'''

# Save documentation
with open("/home/user/skyscope_rag/README.md", "w") as f:
    f.write(docs_content)

# Create a quick setup guide
setup_guide = '''#!/bin/bash
# Skyscope RAG System - Quick Setup Guide

echo "ğŸš€ Skyscope RAG System Setup Starting..."

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama not found. Please install Ollama first:"
    echo "   curl -fsSL https://ollama.ai/install.sh | sh"
    exit 1
fi

# Start Ollama if not running
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "ğŸ”„ Starting Ollama..."
    ollama serve &
    sleep 5
fi

# Pull recommended models
echo "ğŸ“¥ Pulling Ollama models..."
ollama pull codellama
ollama pull nomic-embed-text

# Run Python setup
echo "ğŸ Setting up Python environment..."
python3 /home/user/skyscope_rag/scripts/setup.py

echo "âœ… Setup complete!"
echo ""
echo "ğŸ¯ Next steps:"
echo "1. Index your parquet files:"
echo "   python3 /home/user/skyscope_rag/scripts/main.py index /Users/skyscope.cloud/Documents/github-code"
echo ""
echo "2. Start searching:"
echo "   python3 /home/user/skyscope_rag/scripts/main.py search 'machine learning'"
echo ""
echo "3. Ask questions:"
echo "   python3 /home/user/skyscope_rag/scripts/main.py ask 'How to implement authentication?'"
echo ""
echo "4. Interactive mode:"
echo "   python3 /home/user/skyscope_rag/scripts/main.py interactive"
'''

with open("/home/user/skyscope_rag/setup.sh", "w") as f:
    f.write(setup_guide)

os.chmod("/home/user/skyscope_rag/setup.sh", 0o755)

print("ğŸ“š Documentation created:")
print("  ğŸ“– README.md - Comprehensive documentation")
print("  ğŸ”§ setup.sh - Quick setup script")
print()
print("ğŸ‰ SKYSCOPE RAG SYSTEM COMPLETE!")
print("="*50)
print("âœ… All components implemented and ready")
print("ğŸ“¦ Total files created: 10+")
print("ğŸ§  Features: Semantic search, RAG, agents, memory")
print("ğŸ”§ Ready for deployment on macOS")