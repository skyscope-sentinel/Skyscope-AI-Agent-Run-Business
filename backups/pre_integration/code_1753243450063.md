# ğŸ macOS Installation Guide

## Skyscope AI Agent Business Automation System - macOS Setup

This guide provides comprehensive instructions for installing and configuring the Skyscope AI Agent Business Automation System on macOS, with specific optimizations for Apple Silicon (M1/M2/M3) processors.

---

## ğŸ“‹ **System Requirements**

### **Minimum Requirements**
- **macOS**: 11.0 (Big Sur) or later
- **RAM**: 8GB (16GB recommended for optimal performance) 
- **Storage**: 20GB free disk space
- **Processor**: Intel x64 or Apple Silicon (M1/M2/M3)
- **Internet**: Stable internet connection for initial setup

### **Recommended Configuration**
- **macOS**: 13.0 (Ventura) or later
- **RAM**: 16GB+ (32GB for heavy workloads)
- **Storage**: 50GB+ SSD free space
- **Processor**: Apple Silicon M2 or M3 (for Metal GPU acceleration)
- **Network**: High-speed internet for model downloads

---

## ğŸš€ **Quick Installation**

### **Option 1: Automated Setup (Recommended)**

```bash
# Clone the repository
git clone https://github.com/skyscope-sentinel/Skyscope-AI-Agent-Run-Business.git
cd Skyscope-AI-Agent-Run-Business

# Run the automated macOS setup script
python3 setup_macos.py

# Follow the interactive prompts
```

The automated setup will:
- âœ… Install Homebrew (if not present)
- âœ… Install Python 3.8+ and required dependencies
- âœ… Install and configure Ollama with Metal GPU support
- âœ… Set up virtual environment
- âœ… Install all Python packages
- âœ… Download and configure default AI models
- âœ… Create configuration files
- âœ… Verify installation

---

## ğŸ”§ **Manual Installation**

### **Step 1: Install Prerequisites**

#### **1.1 Install Homebrew**
```bash
# Install Homebrew package manager
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Add Homebrew to PATH (Apple Silicon)
echo 'eval "$(/opt/homebrew/bin/brew shellenv)"' >> ~/.zshrc
source ~/.zshrc

# Verify installation
brew --version
```

#### **1.2 Install Python**
```bash
# Install Python 3.8+ using Homebrew
brew install python@3.11

# Create symlinks for easy access
brew link python@3.11

# Verify Python installation
python3 --version
pip3 --version
```

#### **1.3 Install System Dependencies**
```bash
# Install essential tools
brew install git curl wget node npm

# Install development tools
brew install make gcc cmake

# Install optional but recommended tools
brew install htop tree jq
```

### **Step 2: Install Ollama**

#### **2.1 Download and Install Ollama**
```bash
# Download Ollama installer
curl -fsSL https://ollama.com/install.sh | sh

# Or install via Homebrew
brew install ollama

# Verify installation
ollama --version
```

#### **2.2 Start Ollama Service**
```bash
# Start Ollama as a background service
brew services start ollama

# Or start manually
ollama serve

# Verify service is running
curl http://localhost:11434/api/version
```

#### **2.3 Download AI Models**
```bash
# Download recommended models (this may take 10-30 minutes)
ollama pull llama2:13b          # General purpose model
ollama pull codellama:13b       # Code generation model  
ollama pull mistral:7b          # Fast analysis model
ollama pull vicuna:13b          # Creative tasks model

# Verify models are installed
ollama list
```

### **Step 3: Clone and Setup Repository**

#### **3.1 Clone Repository**
```bash
# Clone the main repository
git clone https://github.com/skyscope-sentinel/Skyscope-AI-Agent-Run-Business.git
cd Skyscope-AI-Agent-Run-Business

# Verify repository structure
ls -la
```

#### **3.2 Create Virtual Environment**
```bash
# Create Python virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate

# Upgrade pip
pip install --upgrade pip
```

#### **3.3 Install Python Dependencies**
```bash
# Install main dependencies
pip install -r requirements.txt

# Install development dependencies (optional)
pip install -r requirements-dev.txt

# Verify installation
pip list
```

### **Step 4: Configuration**

#### **4.1 Create Configuration Files**
```bash
# Copy configuration templates
cp config/config_template.yaml config/config.yaml
cp config/agents/supervisor_config_template.yaml config/agents/supervisor_config.yaml
cp config/agents/research_config_template.yaml config/agents/research_config.yaml
cp config/agents/content_config_template.yaml config/agents/content_config.yaml
cp config/agents/freelance_config_template.yaml config/agents/freelance_config.yaml
cp config/agents/deployment_config_template.yaml config/agents/deployment_config.yaml
```

#### **4.2 Configure System Settings**
Edit `config/config.yaml`:

```yaml
# System Configuration
system:
  name: "Skyscope AI Business System"
  version: "1.0.0"
  environment: "production"
  platform: "macos"
  architecture: "apple_silicon"  # or "intel"
  
# Ollama Configuration  
ollama:
  base_url: "http://localhost:11434"
  models:
    primary: "llama2:13b"
    coding: "codellama:13b"
    analysis: "mistral:7b"
    creative: "vicuna:13b"
  gpu_acceleration: true
  metal_support: true
  max_concurrent_requests: 4

# Performance Settings
performance:
  cache_enabled: true
  cache_size: "2GB"
  database_pooling: true
  async_processing: true
  monitoring_interval: 60
  apple_silicon_optimizations: true
```

#### **4.3 Configure Agent Settings**
Edit agent-specific configuration files in `config/agents/`:

```yaml
# supervisor_config.yaml
supervisor:
  enabled: true
  learning_rate: 0.1
  performance_threshold: 0.8
  crisis_detection_sensitivity: 0.7
  optimization_interval: 300
  apple_silicon_optimized: true

# research_config.yaml  
research:
  enabled: true
  max_concurrent_sources: 8
  research_timeout: 1800
  max_results_per_source: 50
  cache_results: true
  
# content_config.yaml
content:
  enabled: true
  max_concurrent_generation: 5
  platforms: ["linkedin", "twitter", "instagram", "facebook"]
  seo_optimization: true
  brand_consistency_check: true

# freelance_config.yaml
freelance:
  enabled: true
  crm_integration: true
  auto_invoicing: true
  time_tracking: true
  portfolio_updates: true

# deployment_config.yaml
deployment:
  enabled: true
  platforms: ["vercel", "netlify", "aws", "heroku"]
  auto_scaling: true
  performance_monitoring: true
  ssl_auto_config: true
```

### **Step 5: Verification and Testing**

#### **5.1 Run System Tests**
```bash
# Run basic system tests
python -m pytest tests/test_basic_functionality.py

# Run integration tests  
python -m pytest tests/test_integration.py

# Run performance tests
python -m pytest tests/test_performance.py
```

#### **5.2 Verify Ollama Integration**
```bash
# Test Ollama connection
python -c "
import requests
response = requests.get('http://localhost:11434/api/version')
print('Ollama Status:', response.status_code)
print('Version:', response.json() if response.status_code == 200 else 'Error')
"
```

#### **5.3 Test Agent Communication**
```bash
# Run agent communication test
python tests/test_agent_communication.py
```

---

## ğŸ¯ **Launch System**

### **Option 1: Web Interface**
```bash
# Activate virtual environment
source venv/bin/activate

# Launch Streamlit web interface
streamlit run app.py

# Access at: http://localhost:8501
```

### **Option 2: Main Application**
```bash
# Launch main application
python main_application.py

# Follow interactive prompts
```

### **Option 3: API Server**
```bash
# Launch FastAPI server
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload

# Access API docs at: http://localhost:8000/docs
```

---

## âš™ï¸ **macOS-Specific Optimizations**

### **Apple Silicon (M1/M2/M3) Optimizations**

#### **1. Metal GPU Acceleration**
```yaml
# config/config.yaml
ollama:
  metal_support: true
  gpu_layers: 35  # Adjust based on your model size and available VRAM
  gpu_memory_fraction: 0.8
```

#### **2. Memory Management**
```yaml
# Optimize for Apple Silicon unified memory
performance:
  apple_silicon_optimizations: true
  unified_memory_optimization: true
  memory_pressure_handling: true
  background_app_refresh: false
```

#### **3. Performance Tuning**
```bash
# Create performance optimization script
cat > optimize_macos.sh << 'EOF'
#!/bin/bash

# Disable unnecessary background services
sudo launchctl unload -w /System/Library/LaunchDaemons/com.apple.metadata.mds.plist 2>/dev/null || true

# Optimize network settings
sudo sysctl -w net.inet.tcp.delayed_ack=0
sudo sysctl -w net.inet.tcp.slowstart_flightsize=20

# Set process priority
sudo renice -n -10 -p $$

echo "macOS optimizations applied"
EOF

chmod +x optimize_macos.sh
./optimize_macos.sh
```

### **Intel Mac Optimizations**

#### **1. Rosetta 2 Compatibility**
```bash
# Install Rosetta 2 if needed
sudo softwareupdate --install-rosetta --agree-to-license
```

#### **2. Performance Settings**
```yaml
# config/config.yaml for Intel Macs
performance:
  intel_optimizations: true
  cpu_affinity: true
  thread_pool_size: 8
  memory_mapping: true
```

---

## ğŸ”’ **Security Configuration**

### **1. Firewall Settings**
```bash
# Enable macOS firewall
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --setglobalstate on

# Allow Ollama and application ports
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --add /opt/homebrew/bin/ollama
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --unblockapp /opt/homebrew/bin/ollama
```

### **2. Privacy Settings**
```bash
# Grant necessary permissions (run as needed)
# These commands may require user interaction
sudo xattr -r -d com.apple.quarantine /path/to/skyscope-app
```

### **3. Keychain Configuration**
```bash
# Create keychain entry for secure API key storage
security add-generic-password -a "skyscope-api" -s "skyscope-system" -w "your-api-key"

# Access in Python:
# import keyring
# api_key = keyring.get_password("skyscope-system", "skyscope-api")
```

---

## ğŸš¨ **Troubleshooting**

### **Common Issues and Solutions**

#### **1. Ollama Installation Issues**
```bash
# If Ollama fails to start
brew services stop ollama
brew services start ollama

# Check if port is in use
lsof -ti:11434

# Kill conflicting processes
kill -9 $(lsof -ti:11434)
```

#### **2. Python Virtual Environment Issues**
```bash
# If virtual environment creation fails
python3 -m pip install --upgrade pip
python3 -m pip install virtualenv
python3 -m virtualenv venv

# If activation fails
chmod +x venv/bin/activate
source venv/bin/activate
```

#### **3. Model Download Issues**
```bash
# If model downloads fail or are slow
export OLLAMA_HOST=http://localhost:11434
ollama pull llama2:7b  # Try smaller model first

# Clear Ollama cache if needed
rm -rf ~/.ollama/models
ollama pull llama2:13b
```

#### **4. Permission Issues**
```bash
# Fix permission issues
sudo chown -R $(whoami) /opt/homebrew
sudo chown -R $(whoami) ~/.ollama

# Reset permissions
chmod -R 755 ./Skyscope-AI-Agent-Run-Business
```

#### **5. Metal GPU Issues (Apple Silicon)**
```bash
# Check Metal support
system_profiler SPDisplaysDataType | grep Metal

# If Metal acceleration isn't working
export PYTORCH_ENABLE_MPS_FALLBACK=1
export OLLAMA_METAL=1
```

### **Performance Issues**

#### **1. Slow Model Loading**
```yaml
# Optimize model loading
ollama:
  preload_models: true
  model_cache_size: "8GB"
  concurrent_model_loading: false
```

#### **2. Memory Issues**
```bash
# Monitor memory usage
top -o MEM

# Free memory if needed
sudo purge
```

#### **3. Network Issues**
```bash
# Test network connectivity
curl -I http://localhost:11434/api/version
ping -c 4 ollama.com

# Reset network settings if needed
sudo dscacheutil -flushcache
sudo killall -HUP mDNSResponder
```

---

## ğŸ“Š **Monitoring and Maintenance**

### **1. System Monitoring**
```bash
# Create monitoring script
cat > monitor_system.sh << 'EOF'
#!/bin/bash

echo "=== Skyscope System Status ==="
echo "Date: $(date)"
echo ""

echo "Ollama Status:"
curl -s http://localhost:11434/api/version | jq '.' 2>/dev/null || echo "Ollama not responding"
echo ""

echo "System Resources:"
echo "CPU Usage: $(top -l 1 | grep "CPU usage" | awk '{print $3}' | sed 's/%//')"
echo "Memory Pressure: $(memory_pressure | grep "System-wide memory free percentage" | awk '{print $5}')"
echo "Disk Usage: $(df -h / | tail -1 | awk '{print $5}')"

echo ""
echo "Process Status:"
ps aux | grep -E "(ollama|streamlit|uvicorn|python)" | grep -v grep
EOF

chmod +x monitor_system.sh
./monitor_system.sh
```

### **2. Automated Updates**
```bash
# Create update script
cat > update_system.sh << 'EOF'
#!/bin/bash

echo "Updating Skyscope AI System..."

# Update Homebrew packages
brew update && brew upgrade

# Update Ollama
brew upgrade ollama

# Update Python packages
source venv/bin/activate
pip install --upgrade -r requirements.txt

# Update repository
git pull origin main

echo "Update completed!"
EOF

chmod +x update_system.sh
```

### **3. Backup Configuration**
```bash
# Create backup script
cat > backup_config.sh << 'EOF'
#!/bin/bash

BACKUP_DIR="$HOME/skyscope_backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

# Backup configuration files
cp -R config/ "$BACKUP_DIR/"

# Backup custom agents
cp -R src/agents/custom/ "$BACKUP_DIR/" 2>/dev/null || true

# Backup database
cp -R data/ "$BACKUP_DIR/" 2>/dev/null || true

echo "Backup created at: $BACKUP_DIR"
EOF

chmod +x backup_config.sh
```

---

## ğŸ¯ **Next Steps**

After successful installation:

1. **ğŸ“– Read the [Configuration Guide](docs/configuration/README.md)**
2. **ğŸ“ Follow the [Quick Start Tutorial](docs/tutorials/quick_start.md)**
3. **ğŸ”§ Customize your [Agent Configuration](docs/configuration/agents.md)**
4. **ğŸ“Š Set up [Performance Monitoring](docs/monitoring/README.md)**
5. **ğŸš€ Deploy your first [Business Workflow](docs/workflows/README.md)**

---

## ğŸ“ **Support**

If you encounter issues during installation:

- **ğŸ“– Check the [Troubleshooting Guide](docs/troubleshooting/README.md)**
- **ğŸ’¬ Visit our [GitHub Discussions](https://github.com/skyscope-sentinel/Skyscope-AI-Agent-Run-Business/discussions)**
- **ğŸ› Report bugs via [GitHub Issues](https://github.com/skyscope-sentinel/Skyscope-AI-Agent-Run-Business/issues)**
- **ğŸ“§ Email support: support@skyscope-ai.com**

---

**ğŸ‰ Congratulations! Your Skyscope AI Agent Business Automation System is now ready to revolutionize your business operations!**